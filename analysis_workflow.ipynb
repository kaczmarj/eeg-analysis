{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MNE-Python recommends using qt.\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis workflows\n",
    "\n",
    "Look into the [PREP pipeline](http://dx.doi.org/10.3389/fninf.2015.00016) as an example.  \n",
    "What [MNE recommends](http://martinos.org/mne/stable/auto_tutorials/plot_artifacts_correction_ica.html#what-if-we-don-t-have-an-eog-channel) if you do not have an EOG channel.\n",
    "\n",
    "It is a good idea to visually check the data throughout analysis.\n",
    "\n",
    "QUESTIONS\n",
    "---------\n",
    "- Should we filter all of the data, remove bad segments, and then ICA all of the data? Or could we filter --> remove bad segments/channels --> ICA per subject? ICA in MNE is fast enough (~1 min) that I think it is better to do everything per subject.\n",
    "\n",
    "Time-Frequency\n",
    "--------------\n",
    "\n",
    "__By subject__\n",
    "\n",
    "1. Load data\n",
    "1. Bandpass filter (one at a time?)\n",
    "1. Reject artifacts (blinks, flat channels, excessively noisy channels)\n",
    "    - ICA\n",
    "    - To detect noisy/blink components with ICA in many subjects, try `mne.preprocessing.corrmap()`\n",
    "    - how to detect flat channels?\n",
    "1. Epoch\n",
    "    - reject based on peak-to-peak amplitude using `reject` parameter.\n",
    "\n",
    "__By group__\n",
    "\n",
    "1. Statistical analyses\n",
    "\n",
    "Automated artifact rejection\n",
    "----------------------------\n",
    "\n",
    "- SSP (projection vectors)\n",
    "- use `mne.preprocessing.find_eog_events()`\n",
    "- use `mne.preprocessing.run_ica()`\n",
    "- use `mne.preprocessing.ICA.detect_artifacts()`\n",
    "- use `mne.preprocessing.corrmap()`\n",
    "- use flat signal detection\n",
    "- specify `reject` parameter of mne.Epochs\n",
    "\n",
    "We can compute and save ICA solution and save if we want to compute\n",
    "the ICA (longest step) all at once, let's say overnight.\n",
    "Make a script to compute ICA for everyone. We would have to load \n",
    "the raw file and the corresponding ICA solution when removing noisy components.\n",
    "\n",
    "Use `mne.io.Raw.set_montage()` to add the electrode location information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "from mne import (\n",
    "    set_config, set_log_level, io, compute_proj_raw,\n",
    "    pick_types, make_fixed_length_events, Epochs, )\n",
    "from mne.utils import ProgressBar\n",
    "from mne.preprocessing import ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-49537676f917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Change working directory to data folder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# path = os.path.join('data')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: 'data'"
     ]
    }
   ],
   "source": [
    "# Change working directory to data folder.\n",
    "# path = os.path.join('data')\n",
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-21d920258c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "os.path.realpath(__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Configure some MNE settings.\n",
    "# # List of keys can be found in mne.utils.known_config_types\n",
    "# set_config('MNE_STIM_CHANNEL', 'STI101', set_env=True)\n",
    "\n",
    "# Change how much MNE-Python talks.\n",
    "# Verbose can be \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", or \"CRITICAL\".\n",
    "set_log_level(verbose='warning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# How to deal with multiple files per subject/task?\n",
    "raw_fnames = [f for f in glob.glob(\"1_raw/*sudoku*.set\")]\n",
    "print \"Found\", len(raw_fnames), \"matching files\"\n",
    "\n",
    "# In the future, write something to clean up the filenames\n",
    "# and perhaps to include some extra meta-data in the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Workflow for one subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load raw data.\n",
    "raw = io.read_raw_eeglab(raw_fnames[1], preload=True)\n",
    "# If prelaod=False, you can call `raw.load_data()` when necessary.\n",
    "# If you need to remove the instance from memory, just delete the variable\n",
    "# with raw = None\n",
    "\n",
    "# Set filename, which will make it easier to save with informative filenames.\n",
    "raw.info['filename'] = 'NEU_001-sudoku'\n",
    "\n",
    "# Identify which data you want to work with.\n",
    "# Some files have multiple types of data, so pick_types() becomes very useful.\n",
    "raw.pick_types(meg=False, eeg=True, stim=False)\n",
    "\n",
    "# Crop out the first 20 seconds of data.\n",
    "raw.crop(tmin=20.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandpass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_freq = 0.5\n",
    "h_freq = 40.\n",
    "\n",
    "# The output is different between simultaneous bandpass filtering\n",
    "# and separate filtering.\n",
    "\n",
    "# # High- and low-pass filter simultaneously.\n",
    "# raw.filter(l_freq=l_freq, h_freq=h_freq, picks=picks, phase='zero', fir_window='hamming', \n",
    "#            l_trans_bandwidth='auto', h_trans_bandwidth='auto', \n",
    "#            filter_length='auto')\n",
    "\n",
    "# High- and low-pass filter separately.\n",
    "raw.filter(l_freq=l_freq, h_freq=None, phase='zero', fir_window='hamming', \n",
    "           l_trans_bandwidth='auto', h_trans_bandwidth='auto', \n",
    "           filter_length='auto')\n",
    "raw.filter(l_freq=None, h_freq=h_freq, phase='zero', fir_window='hamming', \n",
    "           l_trans_bandwidth='auto', h_trans_bandwidth='auto', \n",
    "           filter_length='auto')\n",
    "\n",
    "# Indicate in the filename that we filtered\n",
    "raw.info['filename'] += '-firfilt'\n",
    "# raw.save(raw.info['filename'] + '.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize data to remove bad channels before the next steps\n",
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Removed channel(s)\", raw.info['bads']\n",
    "raw.pick_types(meg=False, eeg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSP vs using average reference\n",
    "\n",
    "To me, it looks better to use the average reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projection = compute_proj_raw(raw, n_grad=0, n_mag=0, n_eeg=1)\n",
    "raw.copy().add_proj(projection).plot(title=\"Using spatial space projection vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw.copy().set_eeg_reference(None).plot(title=\"Using average reference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use an average reference. None makes it use an average.\n",
    "# Average reference not recommended for anything below 64 channels.\n",
    "raw.set_eeg_reference(None)\n",
    "\n",
    "# Ideally, we would not remove channels after setting the average reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove bad segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inspect data.\n",
    "raw.plot(n_channels=len(raw.ch_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# How do you manually add annotations?\n",
    "\n",
    "# Remove flat channels. You can remove these by selecting them on the plot,\n",
    "# but is there automated detection of flat channels?\n",
    "\n",
    "raw.info['bads'] += []\n",
    "\n",
    "print \"Channels removed:\", raw.info['bads']\n",
    "# Removes channels in raw.info['bads'] by default.\n",
    "raw.pick_types(meg=False, eeg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect data to see the effect of any changes made.\n",
    "raw.plot(n_channels=len(raw.ch_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # The following attempts to repair bad channels.\n",
    "# # https://www.martinos.org/mne/stable/manual/channel_interpolation.html\n",
    "# raw.interpolate_bads(reset_bads=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modify filename to indicate that we removed bad segments.\n",
    "raw.info['filename'] += '-reref-cleaned'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent component analysis (ICA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use extended-infomax algorithm. EEGLAB also uses this algorithm.\n",
    "ica = ICA(method='extended-infomax').fit(raw)\n",
    "\n",
    "# # Save ICA solution.\n",
    "# ica.save(raw.info['filename'] + '-ica.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Click on a component to plot detailed information about it.\n",
    "ica.plot_components(inst=raw)  # Plot topography of ICA components.\n",
    "ica.plot_sources(raw, start=0, stop=10)  # Plot timecourse of components.\n",
    "raw.plot(duration=10)  # Plot raw data to compare to ICA sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw.pick_types(meg=False, eeg=True)\n",
    "\n",
    "# Ideally, you would manually check for EOG components.\n",
    "# But we can compare the EOG components that a rater finds versus\n",
    "# the components this function finds.\n",
    "\n",
    "# Check Fp1 and Fp2, but we must do this separately because find_bads_eog()\n",
    "# does not accept list type for the ch_name parameter.\n",
    "# We set verbose here to only print errors, because otherwise it will\n",
    "# print warnings about changes in default values for the upcoming version.\n",
    "eog_components, eog_scores = ica.find_bads_eog(raw, ch_name='Fp2', verbose='error')\n",
    "\n",
    "# Print the components that it thinks are blinks, and print the \n",
    "# correlation scores of those components.\n",
    "for c in eog_components:\n",
    "    print c, '\\t', eog_scores[c]\n",
    "if not eog_components:\n",
    "    print \"Could not find any EOG components.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# You can specify ica.exclude manually, or you can mark\n",
    "# the components you want to remove in the plot of ICA sources.\n",
    "# Components in ica.exclude will be removed with the apply() method.\n",
    "\n",
    "# [5, 21, 22]\n",
    "\n",
    "# Manually:\n",
    "# ica.exclude += [6, 7, 10]\n",
    "print \"Components marked for removal:\", ica.exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply() zeros out all components in ica.exclude,\n",
    "# and it operates in-place on the instance of Raw or Epochs.\n",
    "# Use a copy of the Raw or Epochs instance if you do not want\n",
    "# apply() to operate in-place.\n",
    "raw_cleaned_with_ica = ica.apply(raw.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_cleaned_with_ica.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove any bad channels selected while viewing the plot.\n",
    "print \"Channels removed:\", raw_cleaned_with_ica.info['bads']\n",
    "raw_cleaned_with_ica.pick_types(meg=False, eeg=True)\n",
    "\n",
    "raw_cleaned_with_ica.info['filename'] += '-pruned_with_ica'\n",
    "# raw_cleaned_with_ica.save(raw.info['filename'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The trigger name we want to give to the epochs.\n",
    "event_id = 1\n",
    "\n",
    "# The desired length of each epoch.\n",
    "epoch_duration = 30.\n",
    "\n",
    "events = make_fixed_length_events(\n",
    "    raw_cleaned_with_ica, event_id, start=0, stop=None,\n",
    "    duration=epoch_duration)\n",
    "\n",
    "# # If our data had included events, we would have used the following.\n",
    "# events = mne.find_events(raw)\n",
    "\n",
    "\n",
    "# What makes the epochs look so wrong? Is it the EEG reference? Detrending? DC offset?\n",
    "# Removing the DC offset seems to help.\n",
    "\n",
    "# Create epochs based on the events created above.\n",
    "epochs = Epochs(\n",
    "    raw_cleaned_with_ica, events, event_id=event_id, tmin=0.0, tmax=epoch_duration, \n",
    "    baseline=None, preload=True, detrend=0, add_eeg_ref=False)\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# epochs.plot()\n",
    "\n",
    "# Plot one epoch.\n",
    "epochs[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs.info['filename'] += '-epochs'\n",
    "epochs.save(epochs.info['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Power\n",
    "\n",
    "Look for theta desync from anything behind Cz (e.g., PO1/2, Oz, O1/2)\n",
    "Check for differences between rest and /_/_ (attention tasks).\n",
    "- Do this for each channel, and check whether multiple channels are significantly different.\n",
    "\n",
    "Multiple comparisons to account for multiple channels / time.\n",
    "\n",
    "Look into `mne.stats.spatio_temporal_permutation_cluster_1samp_test()`\n",
    "Use `stats.fdr_correction()` with p-value of 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
